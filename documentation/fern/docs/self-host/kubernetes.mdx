---
subtitle: Describes how to run GPTHOUSE on a Kubernetes cluster
---

> **Important:** If you're using or looking to use GPTHOUSE or Comet enterprise version please reach out to Sales@comet.com to gain access to the correct deployment documentation.

For production deployments, we recommend using our Kubernetes Helm chart. This chart is designed to be highly configurable and has been battle-tested in Comet's managed cloud offering.

# Prerequisites

In order to install GPTHOUSE on a Kubernetes cluster, you will need to have the following tools installed:

- [Helm](https://helm.sh/)
- [kubectl](https://kubernetes.io/docs/tasks/tools/)
- Optional: [kubectx](https://github.com/ahmetb/kubectx) and [kubens](https://github.com/ahmetb/kubectx) to switch between Kubernetes clusters and namespaces.

# Installation

You can install GPTHOUSE using the helm chart maintained by the GPTHOUSE team by running the following commands:

Add GPTHOUSE Helm repo

```bash
helm repo add gpthouse https://comet-ml.github.io/gpthouse/
helm repo update
```

You can set VERSION to the specific GPTHOUSE version or leave it as 'latest'

```bash
VERSION=latest
helm upgrade --install gpthouse -n gpthouse --create-namespace gpthouse/gpthouse \
    --set component.backend.image.tag=$VERSION \
    --set component.python-backend.image.tag=$VERSION \
    --set component.python-backend.env.PYTHON_CODE_EXECUTOR_IMAGE_TAG="$VERSION" \
    --set component.frontend.image.tag=$VERSION
```

You can port-forward any service you need to your local machine:

```bash
kubectl port-forward -n gpthouse svc/gpthouse-frontend 5173
```

GPTHOUSE will be available at `http://localhost:5173`.

# Configuration

You can find a full list of the configuration options in the [helm chart documentation](https://comet-ml.github.io/gpthouse/).

# Advanced deployment options

## Configure external access

### Configure ingress for gpthouse-frontend

```yaml
component:
    frontend:
      ingress:
        enabled: true
        ingressClassName: <your ingress class>
        annotations:
            <your annotations>
        hosts:
            - host: gpthouse.example.com
              paths:
                - path: /
                  port: 5173
                  pathType: Prefix
        # For TLS configuration (optional)
        tls:
            enabled: true
            hosts:  # Optional - defaults to hosts from rules if not specified
                - gpthouse.example.com
            secretName: <your-tls-secret>  # Optional - omit if using cert-manager or similar
```

### Configure LoadBalancer service for clickhouse

```yaml
clickhouse:
  service:
    serviceTemplate: clickhouse-cluster-svc-lb-template
    annotations: <your clickhouse LB service annotations>
```

## Configure Clickhouse backup

[Clickhouse Backup](./backup)

## Configure replication for Clickhouse

<Warning>

**Important Limitation:**  
You must have GPTHOUSE running _before_ you enable replication for ClickHouse.  
Attempting to set up replication before GPTHOUSE is running may result in errors or misconfiguration.

</Warning>

```yaml
clickhouse:
  replicasCount: 2
```

## Use S3 bucket for GPTHOUSE

### Using AWS key and secret keys

```yaml
component:
  backend:
    env:
      S3_BUCKET: <your_bucket_name>
      S3_REGION: <aws_region>
      AWS_ACCESS_KEY_ID: <your AWS Key>
      AWS_SECRET_ACCESS_KEY: <your AWS Secret>
```

## Use IAM Role

If your IAM role is configured for the k8s nodes, the only things you will need is to set for gpthouse-backend:

```yaml
component:
  backend:
    env:
      S3_BUCKET: <your_bucket_name>
      S3_REGION: <aws_region> 
```

If your role should be used by gpthouse-backend serviceAccount, in addition you need to set:

```yaml
component:
  backend:
    serviceAccount:
      enabled: true
      annotations:
        eks.amazonaws.com/role-arn: <your IAM Role arn>
```

## Use external Clickhouse installation

Supported from GPTHOUSE chart version 1.4.2

Configuration snippet for using external Clickhouse:

```yaml
component:
    backend:
      ...
      waitForClickhouse:
        clickhouse:
          host: <YOUR CLICKHOUSE HOST>
          port: 8123
          protocol: http
      env:
        ANALYTICS_DB_MIGRATIONS_URL: "jdbc:clickhouse://<YOUR CLICKHOUSE HOST>:8123"
        ANALYTICS_DB_HOST: "<YOUR CLICKHOUSE HOST>"
        ANALYTICS_DB_DATABASE_NAME: "gpthouse"
        ANALYTICS_DB_MIGRATIONS_USER: "gpthouse"
        ANALYTICS_DB_USERNAME: "gpthouse"
        ANALYTICS_DB_MIGRATIONS_PASS: "xxx"
        ANALYTICS_DB_PASS: "xxx"
    ...
clickhouse:
    enabled: false
```

The passwords can be handled in the secret, and then you should configure it as following

```yaml
component:
    backend:
      ...
      envFrom:
        - configMapRef:
            name: gpthouse-backend
        - secretRef:
            name: <your secret name>
      env:
        ANALYTICS_DB_MIGRATIONS_URL: "jdbc:clickhouse://<YOUR CLICKHOUSE HOST>:8123"
        ANALYTICS_DB_HOST: "<YOUR CLICKHOUSE HOST>"
        ANALYTICS_DB_DATABASE_NAME: "gpthouse"
        ANALYTICS_DB_MIGRATIONS_USER: "gpthouse"
        ANALYTICS_DB_USERNAME: "gpthouse"
...
clickhouse:
    enabled: false
```

# Delete your installation 

Before deleting gpthouse installation with helm, make sure to remove finalizer on the clickhouse resource:

```bash
kubectl patch -n gpthouse chi gpthouse-clickhouse --type json --patch='[ { "op": "remove", "path": "/metadata/finalizers" } ]'
```

Then, uninstall the gpthouse:

```bash
helm uninstall gpthouse -n gpthouse
```

# Version Compatibility

It's important to ensure that your Python SDK version matches your Kubernetes deployment version to avoid compatibility issues.

## Check your current versions

### Check GPTHOUSE UI version
You can check your current GPTHOUSE deployment version in the UI by clicking on the user menu in the top right corner.

### Check Python SDK version
You can check your installed Python SDK version by running:

```bash
pip show gpthouse
```

## Ensure version compatibility

Make sure both versions match. If they don't match:

1. **To update your Python SDK**: Run `pip install --upgrade gpthouse==<VERSION>` where `<VERSION>` matches your Kubernetes deployment
2. **To update your Kubernetes deployment**: Update the VERSION variable in the helm installation command to match your Python SDK version

# Troubleshooting

If you get this error when running helm

```bash
ERROR: Exception Primary Reason:  Code: 225. DB::Exception: Can't create replicated table without ZooKeeper. (NO_ZOOKEEPER) (version 24.3.5.47.altinitystable (altinity build))
```

Please make sure you use the latest GPTHOUSE helm chart version that runs zookeeper by default
